# SPDX-License-Identifier: Apache-2.0

// #journal-settings
pekko.persistence.r2dbc {
  journal {
    class = "org.apache.pekko.persistence.r2dbc.journal.R2dbcJournal"

    # name of the table to use for events
    table = "event_journal"

    # Otherwise it would be a pinned dispatcher, see https://github.com/akka/akka/issues/31058
    plugin-dispatcher = "pekko.actor.default-dispatcher"

    # Enable this to reduce latency of eventsBySlices. The persisted events will be
    # published as Pekko messages and consumed directly by running eventsBySlices
    # queries. Tradeoff is more CPU and network resources that are used. The events
    # must still be retrieved from the database, but at a lower polling frequency,
    # because delivery of published messages are not guaranteed.
    publish-events = off

    # replay filter not needed for this plugin
    replay-filter.mode = off

    dialect = ${pekko.persistence.r2dbc.dialect}

    schema = ${pekko.persistence.r2dbc.schema}

    use-connection-factory = ${pekko.persistence.r2dbc.use-connection-factory}

    log-db-calls-exceeding = ${pekko.persistence.r2dbc.log-db-calls-exceeding}

    buffer-size = ${pekko.persistence.r2dbc.buffer-size}

    db-timestamp-monotonic-increasing = ${pekko.persistence.r2dbc.db-timestamp-monotonic-increasing}

    use-app-timestamp = ${pekko.persistence.r2dbc.use-app-timestamp}
  }
}
// #journal-settings

// #snapshot-settings
pekko.persistence.r2dbc {
  snapshot {
    class = "org.apache.pekko.persistence.r2dbc.snapshot.R2dbcSnapshotStore"
    table = "snapshot"

    # Otherwise it would be a pinned dispatcher, see https://github.com/akka/akka/issues/31058
    plugin-dispatcher = "pekko.actor.default-dispatcher"

    dialect = ${pekko.persistence.r2dbc.dialect}

    schema = ${pekko.persistence.r2dbc.schema}

    use-connection-factory = ${pekko.persistence.r2dbc.use-connection-factory}

    log-db-calls-exceeding = ${pekko.persistence.r2dbc.log-db-calls-exceeding}
  }
}
// #snapshot-settings

// #durable-state-settings
pekko.persistence.r2dbc {
  # Durable state store
  state {
    class = "org.apache.pekko.persistence.r2dbc.state.R2dbcDurableStateStoreProvider"

    table = "durable_state"

    # When this is enabled the updates verifies that the revision is +1 of
    # previous revision. There might be a small performance gain if
    # this is disabled.
    assert-single-writer = on

    dialect = ${pekko.persistence.r2dbc.dialect}

    schema = ${pekko.persistence.r2dbc.schema}

    use-connection-factory = ${pekko.persistence.r2dbc.use-connection-factory}

    log-db-calls-exceeding = ${pekko.persistence.r2dbc.log-db-calls-exceeding}

    buffer-size = ${pekko.persistence.r2dbc.buffer-size}

    refresh-interval = ${pekko.persistence.r2dbc.refresh-interval}

    behind-current-time = ${pekko.persistence.r2dbc.behind-current-time}
    backtracking {
      enabled = ${pekko.persistence.r2dbc.backtracking.enabled}
      window = ${pekko.persistence.r2dbc.backtracking.window}
      behind-current-time = ${pekko.persistence.r2dbc.backtracking.behind-current-time}
    }

    db-timestamp-monotonic-increasing = ${pekko.persistence.r2dbc.db-timestamp-monotonic-increasing}

    use-app-timestamp = ${pekko.persistence.r2dbc.use-app-timestamp}

    persistence-ids.buffer-size = ${pekko.persistence.r2dbc.persistence-ids.buffer-size}
  }
}
// #durable-state-settings

// #query-settings
pekko.persistence.r2dbc {
  query {
    class = "org.apache.pekko.persistence.r2dbc.query.R2dbcReadJournalProvider"

    table = ${pekko.persistence.r2dbc.journal.table}

    publish-events =  ${pekko.persistence.r2dbc.journal.publish-events}

    # When journal publish-events is enabled a best effort deduplication can be enabled by setting
    # this property to the size of the deduplication buffer in the `eventsBySlices` query.
    # It keeps track of this number of entries and 5000 is recommended capacity. The drawback
    # of enabling this is that when the sequence numbers received via publish-events are out of sync
    # after some error scenarios it will take longer to receive those events, since it will rely on
    # the backtracking queries.
    deduplicate-capacity = 0

    dialect = ${pekko.persistence.r2dbc.dialect}

    schema = ${pekko.persistence.r2dbc.schema}

    use-connection-factory = ${pekko.persistence.r2dbc.use-connection-factory}

    log-db-calls-exceeding = ${pekko.persistence.r2dbc.log-db-calls-exceeding}

    buffer-size = ${pekko.persistence.r2dbc.buffer-size}

    refresh-interval = ${pekko.persistence.r2dbc.refresh-interval}

    behind-current-time = ${pekko.persistence.r2dbc.behind-current-time}
    backtracking {
      enabled = ${pekko.persistence.r2dbc.backtracking.enabled}
      window = ${pekko.persistence.r2dbc.backtracking.window}
      behind-current-time = ${pekko.persistence.r2dbc.backtracking.behind-current-time}
    }

    persistence-ids.buffer-size = ${pekko.persistence.r2dbc.persistence-ids.buffer-size}
  }
}
// #query-settings

// #connection-settings
pekko.persistence.r2dbc {

  # postgres, yugabyte or mysql
  dialect = "postgres"

  # set this to your database schema if applicable, empty by default
  schema = ""

  connection-factory {
    driver = "postgres"

    # the connection can be configured with a url, eg: "r2dbc:postgresql://<host>:5432/<database>"
    url = ""

    # The connection options to be used. Ignored if 'url' is non-empty
    host = "localhost"
    port = 5432
    database = "postgres"
    user = "postgres"
    password = "postgres"

    ssl {
      enabled = off
      # See PostgresqlConnectionFactoryProvider.SSL_MODE
      # Possible values:
      #  allow - encryption if the server insists on it
      #  prefer - encryption if the server supports it
      #  require - encryption enabled and required, but trust network to connect to the right server
      #  verify-ca - encryption enabled and required, and verify server certificate
      #  verify-full - encryption enabled and required, and verify server certificate and hostname
      #  tunnel - use a SSL tunnel instead of following Postgres SSL handshake protocol
      mode = ""

      # Can point to either a resource within the classpath or a file.
      root-cert = ""
    }

    # Initial pool size.
    initial-size = 5
    # Maximum pool size.
    max-size = 20
    # Maximum time to create a new connection.
    connect-timeout = 3 seconds
    # Maximum time to acquire connection from pool.
    acquire-timeout = 5 seconds
    # Number of retries if the connection acquisition attempt fails.
    # In the case the database server was restarted all connections in the pool will
    # be invalid. To recover from that without failed acquire you can use the same number
    # of retries as max-size of the pool
    acquire-retry = 1

    # Maximum idle time of the connection in the pool.
    # Background eviction interval of idle connections is derived from this property
    # and max-life-time.
    max-idle-time = 30 minutes

    # Maximum lifetime of the connection in the pool.
    # Background eviction interval of connections is derived from this property
    # and max-idle-time.
    max-life-time = 60 minutes

    # Configures the statement cache size.
    # 0 means no cache, negative values will select an unbounded cache
    # a positive value will configure a bounded cache with the passed size.
    statement-cache-size = 5000

    # Validate the connection when acquired with this SQL.
    # Enabling this has some performance overhead.
    # A fast query for Postgres is "SELECT 1"
    validation-query = ""

    # FQCN of a ConnectionFactoryOptionsCustomizer. If non-empty, it must be the fully
    # qualified class name of a class implementing the trait ConnectionFactoryOptionsCustomizer.
    # The class must have a constructor with a single parameter of type ActorSystem[_].
    # If this setting is empty, the default no-op customizer will be used.
    connection-factory-options-customizer = ""
  }

  # Fully qualified config path which holds the connection factory configuration.
  # Connection factories are initialized using the config at this path and are identified by the value of this path.
  # All persistence plugins use the same value by default, which allows sharing of single connection factory between all of the plugins.
  use-connection-factory = "pekko.persistence.r2dbc.connection-factory"

  # If database timestamp is guaranteed to not move backwards for two subsequent
  # updates of the same persistenceId there might be a performance gain to
  # set this to `on`. Note that many databases use the system clock and that can
  # move backwards when the system clock is adjusted.
  db-timestamp-monotonic-increasing = off

  # Enable this for testing or workaround of https://github.com/yugabyte/yugabyte-db/issues/10995
  # FIXME: This property will be removed when the Yugabyte issue has been resolved.
  use-app-timestamp = off

  # Logs database calls that take longer than this duration at INFO level.
  # Set to "off" to disable this logging.
  # Set to 0 to log all calls.
  log-db-calls-exceeding = 300 ms

  # In-memory buffer holding events when reading from database.
  buffer-size = 1000

  # When live queries return no results or <= 10% of buffer-size, the next query
  # to db will be delayed for this duration.
  # When the number of rows from previous query is >= 90% of buffer-size, the next
  # query will be emitted immediately.
  # Otherwise, between 10% - 90% of buffer-size, the next query will be delayed
  # for half of this duration.
  refresh-interval = 3s

  # Live queries read events up to this duration from the current database time.
  behind-current-time = 100 millis

  backtracking {
    enabled = on
    # Backtracking queries will look back for this amount of time. It should
    # not be larger than the pekko.projection.r2dbc.offset-store.time-window.
    window = 2 minutes
    # Backtracking queries read events up to this duration from the current database time.
    behind-current-time = 10 seconds
  }

  persistence-ids {
    buffer-size = 1000
  }
}
// #connection-settings
